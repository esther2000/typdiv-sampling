{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85268bf3-4471-4eff-9c62-1a9ee94079ac",
   "metadata": {},
   "source": [
    "### General next-best experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87913504-b75e-4674-945c-71f7e6b2343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typdiv_sampling.distance import get_summed_dist_dict\n",
    "from typdiv_sampling.evaluation import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64aa7616-f1c3-448e-aacb-b3f25457289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\n",
    "    \"flores200.csv\",\n",
    "    \"ud_214.csv\",\n",
    "    \"tydiqa.csv\",\n",
    "    \"xcopa.csv\",\n",
    "    \"aya_eval-human.csv\",\n",
    "]\n",
    "\n",
    "# SELECT PARAMETERS HERE:\n",
    "\n",
    "# Dataset: int (0, 1, 2, 3, 4) corresponding to which dataset to use (see above)\n",
    "D_NUM = 4\n",
    "\n",
    "# Number of languages to add\n",
    "N = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcdbcebc-033e-4f44-af77-3275a28e114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dists(frame, dist_df):\n",
    "    \"\"\"Get language distances for the given frame.\"\"\"\n",
    "    dists = dist_df[frame].loc[frame]\n",
    "    id2lang = dists.columns.tolist()\n",
    "    dists = dists.to_numpy()\n",
    "    return dists, id2lang\n",
    "\n",
    "\n",
    "def sample_maxsum(pre_sample, frame, dist_df, k):\n",
    "    \"\"\"Edited version of the sample code\"\"\"\n",
    "    dists, id2lang = get_dists(frame, dist_df)\n",
    "    all_langs = [i for i in range(len(dists))]\n",
    "    langs = [sorted(frame).index(i) for i in pre_sample]\n",
    "\n",
    "    while len(langs) <= k - 1:\n",
    "        summed_dist = get_summed_dist_dict(dists, all_langs, langs)\n",
    "        next_most_distant = max(summed_dist, key=lambda x: summed_dist[x])\n",
    "        all_langs.remove(next_most_distant)\n",
    "        langs.append(next_most_distant)\n",
    "\n",
    "    return [id2lang[i] for i in langs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f76cf93-0362-4618-9b46-3416f1272931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results for dataset\n",
    "df = pd.read_csv(f\"lang_codes/{DATASETS[D_NUM]}\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf69446b-fe5f-4778-8425-415e9c32409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load language distances\n",
    "dist_df = pd.read_csv(\"../../data/gb_lang_dists.csv\").set_index(\"Unnamed: 0\")\n",
    "dist_dict = dist_df.to_dict(\"dict\")\n",
    "\n",
    "# load grambank\n",
    "gb = pd.read_csv(\"../../data/gb_processed.csv\", index_col=\"Lang_ID\")\n",
    "gb = gb.drop([\"Unnamed: 0\", \"Unnamed: 0.1\"], axis=1)\n",
    "gb.replace(to_replace=\"no_cov\", value=\"?\", inplace=True)\n",
    "gb_by_lang = {i: np.array(row) for i, row in gb.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6164c5c-974f-4281-9ef3-afffb5fcbe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glottocode to language name mapping\n",
    "glt = pd.read_csv(\"../../data/languoid.csv\")\n",
    "gltc_to_name = {r[\"id\"]: r[\"name\"] for _, r in glt.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65f418c-2b35-44b6-a240-acb992a0fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define languages\n",
    "dataset_langs = set(df[\"glottocode\"].to_list())\n",
    "gb_langs = set(gb_by_lang.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d2ae9c-e207-4017-99dc-afb310c493a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have GB data for 5 out of 7 languages.\n"
     ]
    }
   ],
   "source": [
    "# all languages we have data for\n",
    "current_sample = dataset_langs.intersection(gb_langs)\n",
    "print(\n",
    "    f\"We have GB data for {len(current_sample)} out of {len(dataset_langs)} languages.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0b79297-14ab-42cb-9f07-c408b7d1144b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(run=1, ent_score_with=0.6623633424086156, ent_score_without=0.5714527405538357, fvi_score=0.8407960199004975, mpd_score=0.7549133172838374, fvo_score=0.6295528816549381, sample={'mand1415', 'stan1318', 'stan1293', 'nucl1301', 'port1283'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current diversity metrics\n",
    "evaluator = Evaluator(gb_by_lang, dist_dict)\n",
    "res = evaluator.evaluate_sample(current_sample, 1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1b924da-5b8d-4cdd-80d6-f724c7390d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample new\n",
    "k = len(current_sample) + N\n",
    "new_sample = sample_maxsum(list(current_sample), sorted(list(gb_langs)), dist_df, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd95cc4a-f452-4659-912b-193cf563d873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New languages: ['Yele']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(run=1, ent_score_with=0.7841457371605929, ent_score_without=0.6602670669895019, fvi_score=0.8980099502487562, mpd_score=0.7965600701194073, fvo_score=0.5920069229961086, sample={'yele1255', 'mand1415', 'stan1318', 'stan1293', 'nucl1301', 'port1283'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analysis\n",
    "print(\"New languages:\", [gltc_to_name[g] for g in new_sample[-N:]])\n",
    "res = evaluator.evaluate_sample(new_sample, 1)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2156f9b-a66b-46bf-acbe-5f941eea130e",
   "metadata": {},
   "source": [
    "### Case study: UD extension languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc5d2ee8-fe7a-44b0-b74e-872358a75d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load languages\n",
    "df = pd.read_csv(\"lang_codes/ud_214.csv\", sep=\";\")\n",
    "current_langs = set(df[\"glottocode\"].to_list())\n",
    "\n",
    "df_e = pd.read_csv(\"lang_codes/ud_extensions.csv\", sep=\";\")\n",
    "ext_langs = set(df_e[\"glottocode\"].to_list())\n",
    "\n",
    "# intersection and not yet in dataset\n",
    "current_sample = current_langs.intersection(set(dist_df.columns.to_list()))\n",
    "ext_langs = ext_langs.intersection(set(dist_df.columns.to_list()))\n",
    "ext_langs = ext_langs - current_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb9bb30b-544d-46e2-9aed-72a5b2509354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(run=1, ent_score_with=0.8983371130601235, ent_score_without=0.6810527872902721, fvi_score=0.9850746268656716, mpd_score=0.7245766498834872, fvo_score=0.6790589232469976, sample={'yaku1245', 'sout1528', 'tata1255', 'wels1247', 'stan1290', 'nucl1235', 'bela1254', 'nhen1239', 'iris1253', 'faro1244', 'veps1250', 'komi1269', 'russ1264', 'komi1268', 'russ1263', 'stan1289', 'yuec1235', 'esto1258', 'mace1250', 'nucl1643', 'nort2697', 'livv1243', 'mbya1239', 'kore1280', 'zaca1241', 'anci1242', 'bret1244', 'czec1258', 'akka1240', 'erzy1239', 'mala1464', 'gali1258', 'apur1254', 'tswa1253', 'stan1318', 'dani1285', 'stan1293', 'finn1318', 'ital1282', 'malt1254', 'port1283', 'tami1289', 'bhoj1244', 'mund1330', 'west2354', 'jama1261', 'lati1261', 'poli1260', 'hind1269', 'kich1262', 'mara1378', 'xava1240', 'anci1244', 'west2369', 'copt1239', 'chuk1273', 'gheg1238', 'swed1254', 'mode1248', 'mand1415', 'nort2671', 'skol1241', 'boro1282', 'moks1248', 'hebr1245', 'clas1249', 'slov1268', 'hung1274', 'nucl1301', 'icel1247', 'nucl1302', 'akun1241', 'hait1244', 'dutc1256', 'ukra1253', 'latv1249', 'tupi1273', 'abkh1244', 'basq1248', 'lith1251'})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_res = evaluator.evaluate_sample(current_sample, 1)\n",
    "old_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59d6e7b3-3d94-4438-a779-b32bcfaa514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new sampling frame\n",
    "langs = sorted(list(set(list(ext_langs) + list(current_sample))))\n",
    "dist_df = dist_df[langs]\n",
    "dist_df = dist_df.loc[langs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c526d008-e310-4a14-b9ac-c68629b33678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new language: Seri\n"
     ]
    }
   ],
   "source": [
    "# sample with extension language\n",
    "k = len(current_sample) + N\n",
    "new_sample = sample_maxsum(list(current_sample), langs, dist_df, k)\n",
    "print(\"new language:\", gltc_to_name[(set(new_sample) - current_sample).pop()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f70a6a4-243e-42e8-a8e0-9e91c7d1763c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(run=1, ent_score_with=0.9025768344198168, ent_score_without=0.6846505746879855, fvi_score=0.9850746268656716, mpd_score=0.7267890875768118, fvo_score=0.6771515080936407, sample={'yaku1245', 'sout1528', 'tata1255', 'stan1290', 'wels1247', 'iris1253', 'veps1250', 'komi1269', 'russ1263', 'yuec1235', 'esto1258', 'mace1250', 'livv1243', 'kore1280', 'anci1242', 'bret1244', 'czec1258', 'erzy1239', 'mala1464', 'apur1254', 'tswa1253', 'stan1318', 'dani1285', 'stan1293', 'ital1282', 'malt1254', 'port1283', 'mund1330', 'west2354', 'jama1261', 'lati1261', 'poli1260', 'kich1262', 'west2369', 'chuk1273', 'gheg1238', 'mand1415', 'boro1282', 'clas1249', 'hung1274', 'akun1241', 'ukra1253', 'latv1249', 'tupi1273', 'nucl1235', 'bela1254', 'nhen1239', 'faro1244', 'russ1264', 'komi1268', 'stan1289', 'nucl1643', 'nort2697', 'mbya1239', 'zaca1241', 'akka1240', 'gali1258', 'finn1318', 'tami1289', 'bhoj1244', 'seri1257', 'hind1269', 'mara1378', 'xava1240', 'anci1244', 'copt1239', 'swed1254', 'mode1248', 'nort2671', 'skol1241', 'moks1248', 'hebr1245', 'slov1268', 'nucl1301', 'icel1247', 'nucl1302', 'hait1244', 'dutc1256', 'abkh1244', 'basq1248', 'lith1251'})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate diversity\n",
    "new_res = evaluator.evaluate_sample(new_sample, 1)\n",
    "new_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
